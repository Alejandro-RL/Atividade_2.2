# -*- coding: utf-8 -*-
"""script_py_PP2.2.3 - Validação Cruzada e Busca em Grade.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S2ItMni7r9_mwknIYRsxjDuNMoRhOs1w
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import confusion_matrix, balanced_accuracy_score,f1_score,precision_score,recall_score
from sklearn.model_selection import GridSearchCV  
from joblib import dump, load

def validation(rede, X_test_std,y_test, p = True):
  y_pred = rede.predict(X_test_std)
  cmatrix = confusion_matrix(y_test,y_pred)
  
  #6.2 Acurácia
  acc = balanced_accuracy_score(y_test,y_pred,adjusted=False)
  

  #6.4 Precisão
  pre = precision_score(y_test,y_pred,average='weighted')
  

  #6.5 Revocação 
  rev = recall_score(y_test,y_pred,average='weighted')
  

  #6.3 F-Score
  f1 = f1_score(y_test,y_pred,average='weighted')
  

  if (p):
    print("Matriz de confusão:\n")
    print(cmatrix)
    print("\nAcurácia: ",acc)
    print("\nPrecisão: ",pre)
    print("\nRevocação: ",rev)
    print("\nF-Score: ",f1)
  return cmatrix, acc, pre, rev, f1

df = pd.read_csv('/home/elloa/rna2021.1/covtype.csv')

X_train = df[df.columns[0:10]]
y_train = df[df.columns[-1]]

X_train_std = (X_train - np.mean(X_train))/np.std(X_train)

#Melhores  6 Redes do Trabalho Anterior, por 15 Repetições
#Conseguimos melhores resultados sem os atributos categóricos
redes = [[] for i in range(6)] 
redes[0] = MLPClassifier(hidden_layer_sizes=(30,40),activation='logistic',max_iter=200,solver="adam")
redes[1] = MLPClassifier(hidden_layer_sizes=(10,15),activation='tanh',max_iter=200,solver="adam")
redes[2] = MLPClassifier(hidden_layer_sizes=(10,15),activation='relu',max_iter=150,solver="adam")
redes[3] = MLPClassifier(hidden_layer_sizes=(25,25),activation='tanh',max_iter=200,solver="adam")
redes[4] = MLPClassifier(hidden_layer_sizes=(25,25),activation='tanh',max_iter=100,solver="adam")
redes[5] = MLPClassifier(hidden_layer_sizes=(25,25),activation='relu',max_iter=100,solver="adam")

'''

Rede de índice:  0
Acurácia Média:  0.6625432510864768
F-Score Médio:   0.8036498803809674

Rede de índice:  1
Acurácia Média:  0.5381018340996561
F-Score Médio:   0.7439390815931607

Rede de índice:  2
Acurácia Média:  0.5429059643905464
F-Score Médio:   0.7346680900384723

Rede de índice:  3
Acurácia Média:  0.6442603044172408
F-Score Médio:   0.7942627494389778

Rede de índice:  4
Acurácia Média:  0.6311301344393269
F-Score Médio:   0.7901136926854332

Rede de índice:  5
Acurácia Média:  0.6233769019863493
F-Score Médio:   0.7740351681237906
'''

'''
Hiperparâmetros
A. Solver - ‘sgd’, ‘adam’
B. Batch Size -  inteiro (default = batch_size=min(200, n_samples))
C. Learning Rate Init - float (default=0.001)
D. Paciência (n_iter_no_change) - inteiro (default=10)
E. Épocas (max_iter) - inteiro (default=200)
'''

#2 possibilidades para os 5 parâmetros = 32 combinações possíveis
parameters = {'solver':['sgd','adam'],'batch_size':[300,600],
              'learning_rate_init':[0.0001,0.01],'n_iter_no_change':[5,25],
              'max_iter':[100,200]}

grids = [[] for i in range(6)]
for i in range(len(redes)):
  grids[i] = GridSearchCV(redes[i],parameters,n_jobs=-1,scoring='f1_weighted',cv=5)
  grids[i].fit(X_train_std,y_train)

f1_cv = [[] for i in range(6)]
for i in range(len(grids)):
  print('Rede de índice: ',i)
  print("Melhores parâmetros: ",grids[i].best_params_)
  print("F1 usando os melhores parâmetros",grids[i].score(X_train_std,y_train))
  f1_cv[i] = grids[i].score(X_train_std,y_train)
  print()

f1 = [0.8036498803809674, 0.7439390815931607,0.7346680900384723,0.7942627494389778,0.7901136926854332,0.7740351681237906]

print(f"F1: {f1}")
print(f"f1_cv: {f1_cv}")

max_value = max(f1_cv)
max_index = f1_cv.index(max_value)
print("A rede com o maior F-Score foi a Rede",max_index)
print("Com F-Score de: ",max_value)

print("Os parâmetros usados para chegar nesse resultado:")
print("Parâmetros da rede em sí: ",grids[max_index].estimator)
print("Melhor combinação de parâmetros encontrados na busca em grade: ", grids[max_index].best_params_)

results = pd.DataFrame(grids[max_index].cv_results_)
print(results)

#2
#Pegando todos os dados
X = df[df.columns[0:54]]
y = df[df.columns[-1]]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,train_size=0.7,shuffle=True,random_state=42)
X_train_std = (X_train - np.mean(X_train))/np.std(X_train)
X_test_std = (X_test - np.mean(X_train))/np.std(X_train)

#Colocando os melhores parâmetros na rede
melhores_params = grids[max_index].best_params_
melhor_rede = redes[max_index]
melhor_rede.set_params(**melhores_params)

#Treinando 
melhor_rede.fit(X_train_std,y_train)

#3
dump(melhor_rede, 'melhor_rede.joblib')

#4
melhor_rede1 = load('melhor_rede.joblib')

#5
validation(melhor_rede1,X_test_std, y_test)